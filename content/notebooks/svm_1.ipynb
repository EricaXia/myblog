{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "## What is a SVM? \n",
    "\n",
    "A support vector machine is a supervised learning algorithm, that can be used for both classification and regression, but mostly classification. SVMs classify data by finding a hyperplane (\"dividing line\" that splits the input variables) between the classes in the training data. The hyperplane **maximizes the distance between the hyperplane and the closest data points (the \"margin\")**.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/469/0*j6b6qNc-E0RfBxFj\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## How does the SVM draw the hyperplane?\n",
    "\n",
    "The hyperplane is chosen as the dividing line which separates the data points *as widely as possible*, hence why the margin is maximized. First, the SVM draws \"Support Vectors\", that is, two hyperplanes with one intersecting the first data point of class A and the other intersecting the first data point of class B. Then the final hyperplane is drawn in the middle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## How are SVM algorithms implemented in practice?\n",
    "\n",
    "We use something called the *kernel trick*. Basically, the lower-dimensional input data set is transformed, using linear algebra, into a higher-dimensional space. Why? So it will be easier to find a hyperplane that can separate the data. See the image for a visual example.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/0*ZnINGVLyQZfrcZYG\">\n",
    "\n",
    "How do we implement the kernel trick? The linear SVM can be transformed by computing the **inner product** of any two given observations. The inner product of two input vectors is the sum of each pair of input values multipled together.\n",
    "\n",
    "A **kernel function** is the function that transforms the input data. Types of kernel functions used in SVM include:\n",
    "- Linear kernel (as mentioned above, compute the inner product)\n",
    "- Polynomial kernel\n",
    "- RBF (Radial Basis Function) kernel\n",
    "\n",
    "\n",
    "We would need to use polynomial or RBF (more common) if the data set is not linearly separable. \n",
    "\n",
    "### Polynomial kernel\n",
    "Instead of using inner product, we can use a polynomial kernel function to transform the input vectors x_1 and x_2. \n",
    "\n",
    "$$ K(x_1, x_2) = (x_1^Tx_2 + c)^d $$\n",
    "\n",
    "### RBG kernel\n",
    "Defined mathematically as\n",
    "\n",
    "$$ K(x_1, x_2) = exp(-\\frac{|| x_1 - x_2 ||^2}{2\\sigma^2}) $$\n",
    "\n",
    "And note that the $|| x_1 - x_2||^2$ is the squared Euclidean distance between two feature vectors, and $\\sigma$ is a free parameter."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## When would you use SVM over Random Forest?\n",
    "* When the data set is not linearly separable. Then SVM can use the kernel trick, such as with RBF kernel.\n",
    "* When the data is very high-dimensional. For example in text classification and other NLP problems.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Links\n",
    "https://machinelearningmastery.com/support-vector-machines-for-machine-learning/\n",
    "https://en.wikipedia.org/wiki/Support-vector_machine\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}